{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f205f077-501c-443b-9621-614f9365c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hist\\miniconda3\\envs\\py38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import hashlib\n",
    "import platform\n",
    "import itertools\n",
    "import collections\n",
    "import pkg_resources  # pip install py-rouge\n",
    "from io import open\n",
    "from konlpy.tag import Mecab \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, EarlyStoppingCallback, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facfed46-d560-4ed1-a404-56476b58d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer arguments\n",
    "lr = 1e-4\n",
    "stop = 3\n",
    "epoch = 1000\n",
    "batch = 2\n",
    "seed = 42\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749fa23-4c11-4378-ae4b-7a1f2cf36614",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52af1a5e-1e96-48b7-8ad4-9d4a797debf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AwsS3Downloader(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        aws_access_key_id=None,\n",
    "        aws_secret_access_key=None,\n",
    "    ):\n",
    "        self.resource = boto3.Session(\n",
    "            aws_access_key_id=aws_access_key_id,\n",
    "            aws_secret_access_key=aws_secret_access_key,\n",
    "        ).resource(\"s3\")\n",
    "        self.client = boto3.client(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=aws_access_key_id,\n",
    "            aws_secret_access_key=aws_secret_access_key,\n",
    "            config=Config(signature_version=UNSIGNED),\n",
    "        )\n",
    "\n",
    "    def __split_url(self, url: str):\n",
    "        if url.startswith(\"s3://\"):\n",
    "            url = url.replace(\"s3://\", \"\")\n",
    "        bucket, key = url.split(\"/\", maxsplit=1)\n",
    "        return bucket, key\n",
    "\n",
    "    def download(self, url: str, local_dir: str):\n",
    "        bucket, key = self.__split_url(url)\n",
    "        filename = os.path.basename(key)\n",
    "        file_path = os.path.join(local_dir, filename)\n",
    "\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        meta_data = self.client.head_object(Bucket=bucket, Key=key)\n",
    "        total_length = int(meta_data.get(\"ContentLength\", 0))\n",
    "\n",
    "        downloaded = 0\n",
    "\n",
    "        def progress(chunk):\n",
    "            nonlocal downloaded\n",
    "            downloaded += chunk\n",
    "            done = int(50 * downloaded / total_length)\n",
    "            sys.stdout.write(\n",
    "                \"\\r{}[{}{}]\".format(file_path, \"█\" * done, \".\" * (50 - done))\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                self.client.download_fileobj(bucket, key, f, Callback=progress)\n",
    "            sys.stdout.write(\"\\n\")\n",
    "            sys.stdout.flush()\n",
    "        except:\n",
    "            raise Exception(f\"downloading file is failed. {url}\")\n",
    "        return file_path\n",
    "\n",
    "def download(url, chksum=None, cachedir=\".cache\"):\n",
    "    cachedir_full = os.path.join(os.getcwd(), cachedir)\n",
    "    os.makedirs(cachedir_full, exist_ok=True)\n",
    "    filename = os.path.basename(url)\n",
    "    file_path = os.path.join(cachedir_full, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        if hashlib.md5(open(file_path, \"rb\").read()).hexdigest()[:10] == chksum:\n",
    "            print(f\"using cached model. {file_path}\")\n",
    "            return file_path, True\n",
    "\n",
    "    s3 = AwsS3Downloader()\n",
    "    file_path = s3.download(url, cachedir_full)\n",
    "    if chksum:\n",
    "        assert (\n",
    "            chksum == hashlib.md5(open(file_path, \"rb\").read()).hexdigest()[:10]\n",
    "        ), \"corrupted file!\"\n",
    "    return file_path, False\n",
    "\n",
    "def get_kobart_tokenizer(cachedir=\".cache\"):\n",
    "    \"\"\"Get KoGPT2 Tokenizer file path after downloading\"\"\"\n",
    "    tokenizer = {\n",
    "        \"url\": \"s3://skt-lsl-nlp-model/KoBART/tokenizers/kobart_base_tokenizer_cased_cf74400bce.zip\",\n",
    "        \"chksum\": \"cf74400bce\",\n",
    "    }\n",
    "    file_path, is_cached = download(\n",
    "        tokenizer[\"url\"], tokenizer[\"chksum\"], cachedir=cachedir\n",
    "    )\n",
    "    cachedir_full = os.path.expanduser(cachedir)\n",
    "    if (\n",
    "        not os.path.exists(os.path.join(cachedir_full, \"emji_tokenizer\"))\n",
    "        or not is_cached\n",
    "    ):\n",
    "        if not is_cached:\n",
    "            shutil.rmtree(\n",
    "                os.path.join(cachedir_full, \"emji_tokenizer\"), ignore_errors=True\n",
    "            )\n",
    "        zipf = ZipFile(os.path.expanduser(file_path))\n",
    "        zipf.extractall(path=cachedir_full)\n",
    "    tok_path = os.path.join(cachedir_full, \"emji_tokenizer/model.json\")\n",
    "    tokenizer_obj = PreTrainedTokenizerFast(\n",
    "        tokenizer_file=tok_path,\n",
    "        bos_token=\"<s>\",\n",
    "        eos_token=\"</s>\",\n",
    "        unk_token=\"<unk>\",\n",
    "        pad_token=\"<pad>\",\n",
    "        mask_token=\"<mask>\",\n",
    "    )\n",
    "    return tokenizer_obj\n",
    "\n",
    "def get_pytorch_kobart_model(ctx=\"cpu\", cachedir=\".cache\"):\n",
    "    pytorch_kobart = {\n",
    "        \"url\": \"s3://skt-lsl-nlp-model/KoBART/models/kobart_base_cased_ff4bda5738.zip\",\n",
    "        \"chksum\": \"ff4bda5738\",\n",
    "    }\n",
    "    model_zip, is_cached = download(\n",
    "        pytorch_kobart[\"url\"], pytorch_kobart[\"chksum\"], cachedir=cachedir\n",
    "    )\n",
    "    cachedir_full = os.path.join(os.getcwd(), cachedir)\n",
    "    model_path = os.path.join(cachedir_full, \"kobart_from_pretrained\")\n",
    "    if not os.path.exists(model_path) or not is_cached:\n",
    "        if not is_cached:\n",
    "            shutil.rmtree(model_path, ignore_errors=True)\n",
    "        zipf = ZipFile(os.path.expanduser(model_zip))\n",
    "        zipf.extractall(path=cachedir_full)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d000bf5f-3255-4995-a8b5-0312a863809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(phase):\n",
    "    work_dir = \"C:\\\\Users\\\\hist\\\\Documents\\\\GitHub\\\\KoBART\"\n",
    "    if phase == 'train':\n",
    "        tmp = work_dir+'/022.요약문 및 레포트 생성 데이터/01.데이터/1.Training/라벨링데이터/TL1'\n",
    "    else:\n",
    "        tmp = work_dir+'/022.요약문 및 레포트 생성 데이터/01.데이터/2.Validation/라벨링데이터/VL1'\n",
    "    listdir = os.listdir(tmp)\n",
    "    df = pd.DataFrame({}, columns = ['genre', 'text', 'label'])\n",
    "    for i in listdir:\n",
    "        files = os.listdir(f'{tmp}/{i}/2~3sent')\n",
    "        for f in tqdm(files):\n",
    "            with open(f'{tmp}/{i}/2~3sent/{f}', 'r', encoding='utf-8') as json_file:\n",
    "                j = json.loads(json_file.read())\n",
    "                df2 = pd.DataFrame.from_dict([{'genre' : i, \n",
    "                                               'text'  : j['Meta(Refine)']['passage'], \n",
    "                                               'label' : j['Annotation']['summary1']}])\n",
    "                df = pd.concat([df, df2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8e76f6-4842-4a72-9aa3-199d485162f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# train = make_df('train').reset_index(drop=True)\n",
    "# val = make_df('val').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6ee0bd-7fbe-48c4-baa2-9b3437f20c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_parquet('train.parquet')\n",
    "# val.to_parquet('val.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c585aecd-26da-4842-a0bb-4c664674508d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.briefing</td>\n",
       "      <td>공정위, 코로나19 피해 사업자의 자료 제출 부담 완화 조치\\n 피심인 의견서 제출...</td>\n",
       "      <td>사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05.minute</td>\n",
       "      <td>중앙선거관리위원회사무총장 김용희] \"예 맞습니다.\"\\n임수경 위원] \"이 공문서를 ...</td>\n",
       "      <td>중앙선거관리위원회사무총장 김 씨는 당에서 유권해석을 질의한 것을 사무처의 생각만으로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08.speech</td>\n",
       "      <td>안녕하십니까? 중소기업청 기술협력과장 장대교입니다. 국내 중소기업은 87%가 기술인...</td>\n",
       "      <td>중소기업청은 2012년 중소기업 기술전문가 연계·과제해결 지원 사업을 공고하여 사업...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02.briefing</td>\n",
       "      <td>농촌진흥청(청장 김경규)은 봄철 이후 증가하는 변비 증상을 완화하는 약용작물로 참...</td>\n",
       "      <td>농촌진흥청은 봄에 몸속 진액이 말라 배변이 힘들어지는 변비 증상을 약화시키는 약용작...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03.his_cul</td>\n",
       "      <td>조선 숙종 때의 문신이자 학자인 노봉 민정중(1628∼1692)의 시문집을 새긴 목...</td>\n",
       "      <td>노봉 민정중의 시문집 목판은 정조 8년 판을 새겼으며 전남 장흥 연곡서원에 소장되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.narration</td>\n",
       "      <td>맞은 편에 있는 같은 양식에 있는 건물은 라이트너 박물관이다.\\n그 앞에는 1565...</td>\n",
       "      <td>라이트너 박물관 앞에는 스페인 장군 아빌레스의 동상이 서 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02.briefing</td>\n",
       "      <td>행정안전부(장관 진영)는 최근 지자체별로 건설이 증가하고 있으나 설계와 유지관리 ...</td>\n",
       "      <td>행정안전부는 지자체별로 건설이 증가하고 있으나 설계와 유지관리 기준이 없어 안전 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09.literature</td>\n",
       "      <td>이때에 조정에서는 북벌──북쪽으로 청국을 칠 계획을 세우고, 여러가 지로 준비을 ...</td>\n",
       "      <td>우리를 정복한 것이 청나라나 명나라의 차이가 아니라 항복하여 종노릇 한 것이 부끄러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>02.briefing</td>\n",
       "      <td>▶행복도시 산울리(63생활권) 공동주택 설계공모 당선작 발표\\n 행정중심복합도시건설...</td>\n",
       "      <td>행복도시 산울리 공동주택 설계공모 당선작은 바람길 확보로 미세먼지 저감을 유도하고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05.minute</td>\n",
       "      <td>법무부장관직무대리 이창재] \"지금 중대한 이익이 있었는지 여부를 포함해서 또 이게 ...</td>\n",
       "      <td>이 법무부장관직무대리는 중대한 이익이 있었는지 소송 대상이 되는지에 대해 법원의 판...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           genre                                               text  \\\n",
       "0    02.briefing  공정위, 코로나19 피해 사업자의 자료 제출 부담 완화 조치\\n 피심인 의견서 제출...   \n",
       "1      05.minute  중앙선거관리위원회사무총장 김용희] \"예 맞습니다.\"\\n임수경 위원] \"이 공문서를 ...   \n",
       "2      08.speech  안녕하십니까? 중소기업청 기술협력과장 장대교입니다. 국내 중소기업은 87%가 기술인...   \n",
       "3    02.briefing   농촌진흥청(청장 김경규)은 봄철 이후 증가하는 변비 증상을 완화하는 약용작물로 참...   \n",
       "4     03.his_cul  조선 숙종 때의 문신이자 학자인 노봉 민정중(1628∼1692)의 시문집을 새긴 목...   \n",
       "5   10.narration  맞은 편에 있는 같은 양식에 있는 건물은 라이트너 박물관이다.\\n그 앞에는 1565...   \n",
       "6    02.briefing   행정안전부(장관 진영)는 최근 지자체별로 건설이 증가하고 있으나 설계와 유지관리 ...   \n",
       "7  09.literature   이때에 조정에서는 북벌──북쪽으로 청국을 칠 계획을 세우고, 여러가 지로 준비을 ...   \n",
       "8    02.briefing  ▶행복도시 산울리(63생활권) 공동주택 설계공모 당선작 발표\\n 행정중심복합도시건설...   \n",
       "9      05.minute  법무부장관직무대리 이창재] \"지금 중대한 이익이 있었는지 여부를 포함해서 또 이게 ...   \n",
       "\n",
       "                                               label  \n",
       "0  사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를...  \n",
       "1  중앙선거관리위원회사무총장 김 씨는 당에서 유권해석을 질의한 것을 사무처의 생각만으로...  \n",
       "2  중소기업청은 2012년 중소기업 기술전문가 연계·과제해결 지원 사업을 공고하여 사업...  \n",
       "3  농촌진흥청은 봄에 몸속 진액이 말라 배변이 힘들어지는 변비 증상을 약화시키는 약용작...  \n",
       "4  노봉 민정중의 시문집 목판은 정조 8년 판을 새겼으며 전남 장흥 연곡서원에 소장되어...  \n",
       "5                라이트너 박물관 앞에는 스페인 장군 아빌레스의 동상이 서 있다.  \n",
       "6  행정안전부는 지자체별로 건설이 증가하고 있으나 설계와 유지관리 기준이 없어 안전 사...  \n",
       "7  우리를 정복한 것이 청나라나 명나라의 차이가 아니라 항복하여 종노릇 한 것이 부끄러...  \n",
       "8  행복도시 산울리 공동주택 설계공모 당선작은 바람길 확보로 미세먼지 저감을 유도하고 ...  \n",
       "9  이 법무부장관직무대리는 중대한 이익이 있었는지 소송 대상이 되는지에 대해 법원의 판...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_parquet('train.parquet')\n",
    "val = pd.read_parquet('val.parquet')\n",
    "val = val.sample(n=10, replace=False).reset_index(drop=True)\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236632ac-68ab-40f1-a345-df7feb5aebd2",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0df920-1331-4896-b591-0f8d1e536fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocss(df):\n",
    "    df.text = df.text.apply(lambda x : re.sub('\\n', ' ',  x))\n",
    "    df.text = df.text.apply(lambda x : re.sub(' +', ' ',  x).strip())\n",
    "    return df\n",
    "\n",
    "train = preprocss(train)\n",
    "val = preprocss(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b593e39-9bad-4a94-9253-a0ecfa3bde08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'공정위, 코로나19 피해 사업자의 자료 제출 부담 완화 조치 피심인 의견서 제출 기한도 코로나19 진정 시까지 한시적으로 연장 운영 공정위는 공정한 거래 질서 확립 및 소비자 보호 등을 위하여 소관 법령을 통해 사업자에게 각종 자료 제출 의무를 부과하고 있으며, 법 위반 행위 심의의결 과정에서는, 당사자의 방어권 보장을 위하여 사업자(피심인)에게 해당 사건의 심사 보고서를 송부하면서 이에 대한 의견을 제출할 수 있도록 하고 있다. 최근 코로나19 확산에 따른 사업자들의 정상적인 경제경영 활동에 어려움으로 인하여 일부 사업자가 법에서 정한 기한 내에 자료를 제출하는데 지장을 겪고 있을 것으로 예상되므로, 원칙적으로는 사업자가 기한 내에 자료를 제출하지 않으면 과태료를 부과해야 하나, 최근 우리 기업들이 처해있는 불가피한 사정을 충분히 고려하여 사업자의 부담을 덜어 줄 필요가 있다. 또한, 기업의 재택 근무 확산 등으로 인하여 피심인이 의견 제출을 위한 자료 수집 등에 많은 어려움이 있을 것으로 예상되는 만큼, 기업의 충분한 방어권 보장을 위한 선제적인 조치가 필요하다. 공정위는 코로나19 확산 등에 대응하여, 사업자의 부담 경감을 위한 조치들을 다음과 같이 시행한다. 할부거래법에 따른 감사 보고서 제출(법 제18조의2 및 제53조) (관련 규정) 선불식 할부거래업자(이하 상조업체)는 회계연도 종료 후 3개월 내에 회계 감사 보고서를 공정위에 제출해야 하며, 이를 위반하는 상조업체에는 3,000만 원 이하의 과태료를 부과한다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5314e71-d4c6-4854-9a55-f21ba19e5500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.loc[0, 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04c8a62-20e5-4e03-a233-d46bd31414b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.str.len().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c8bce-85f3-4df7-86fd-a997b4cf45f0",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ced9f18-c3aa-4807-8047-351cb8a90d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBARTSumDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.df = df\n",
    "        self.len = len(self.df)\n",
    "\n",
    "        self.pad_index = self.tokenizer.pad_token_id\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def add_padding_data(self, inputs):\n",
    "        if len(inputs) < self.max_len:\n",
    "            pad = np.array([self.pad_index] *(self.max_len - len(inputs)))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:self.max_len]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def add_ignored_data(self, inputs):\n",
    "        if len(inputs) < self.max_len:\n",
    "            pad = np.array([self.ignore_index] *(self.max_len - len(inputs)))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:self.max_len]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.df.iloc[idx]\n",
    "        input_ids = self.tokenizer.encode(instance['text'])\n",
    "        input_ids = self.add_padding_data(input_ids)\n",
    "\n",
    "        label_ids = self.tokenizer.encode(instance['label'])\n",
    "        label_ids.append(self.tokenizer.eos_token_id)\n",
    "        dec_input_ids = [self.tokenizer.eos_token_id]\n",
    "        dec_input_ids += label_ids[:-1]\n",
    "        dec_input_ids = self.add_padding_data(dec_input_ids)\n",
    "        label_ids = self.add_ignored_data(label_ids)\n",
    "    \n",
    "        return {'input_ids': np.array(input_ids, dtype=np.int_),\n",
    "                'labels': np.array(dec_input_ids, dtype=np.int_),}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b74843-6691-4e39-acf2-628b7cc0bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. C:\\Users\\hist\\Documents\\GitHub\\KoBART\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. C:\\Users\\hist\\Documents\\GitHub\\KoBART\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    }
   ],
   "source": [
    "train_dataset = KoBARTSumDataset(train, get_kobart_tokenizer(), 256)\n",
    "val_dataset = KoBARTSumDataset(val, get_kobart_tokenizer(), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4173ad-7571-4186-aa01-18d32724cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([16735, 12335, 11821, 14031, 10952, 11841, 11810, 14299, 14143,\n",
       "        16121, 15991, 19858,  1543, 18044, 11914, 14085, 10770,  9092,\n",
       "        18025, 10496, 15116, 19211, 14141, 16749, 14862, 14245, 14243,\n",
       "        16344, 14671, 14725, 14483, 11471,   245, 16735, 10952, 11810,\n",
       "        17301, 12007, 14067,  9034, 14143, 16121, 15991, 19858, 18463,\n",
       "        22075, 23658, 14189, 16367, 19775, 11214, 14807, 15425, 25437,\n",
       "        12005, 21308, 11786, 14114, 12332, 21245, 14174, 11264, 11950,\n",
       "        14101, 15460, 12074, 14105, 12005, 18817, 11846, 10226, 14130,\n",
       "        16414, 28403, 19790, 17454, 13469, 17242, 14311, 23449, 25891,\n",
       "         9714,   243, 14040, 16267, 14075, 10500, 10788, 12060, 13590,\n",
       "        16338, 11786, 15859, 12007, 16904, 16728, 16261, 22075, 19727,\n",
       "        16922, 17125, 14130, 26294, 14038, 27368, 14328, 14048, 14038,\n",
       "        13672, 12333, 14410, 20122, 14736, 18154, 14144, 16626, 14737,\n",
       "        16527, 15735,  9103, 14159, 14532, 11950, 14130, 14281, 16781,\n",
       "        15962, 15262,  9760, 14160, 12346, 16247, 20388, 15196, 14108,\n",
       "        28403, 14196,  9993,  9066, 14673,  9698, 19454, 22887, 15029,\n",
       "        27375, 14346, 20602, 14583, 21368, 12005, 23962, 14959, 15135,\n",
       "        14473, 12034,   373, 11028, 10770,  9092,   239, 12865, 12034,\n",
       "        16589,   373, 11028, 19132,   240, 15196, 14108, 10215, 14244,\n",
       "        16247, 14169,  9123, 11908, 14038, 16277, 15063, 14025, 10671,\n",
       "        11810, 16863, 11863, 14270, 16735, 12471, 14248, 10512,  8981,\n",
       "        14083, 10293, 12034, 16634, 24294, 29815, 15033, 15615, 14038,\n",
       "         9133, 13758, 14288, 14527, 14596, 14318, 19754, 17942, 16954,\n",
       "        16338, 11264, 14222, 18433, 14863, 16636, 15442, 27134, 16247,\n",
       "        17507, 11841, 14957, 23412, 14325, 15302, 26294, 14038, 18173,\n",
       "        22809, 14561, 15964, 14196, 15521, 14143, 12865, 10770, 16058,\n",
       "        17045, 21766, 12037, 14775,  9160, 11699, 23373, 14188, 19290,\n",
       "        25686, 14040, 19887, 28816, 14449, 14059, 16247, 14554, 14038,\n",
       "        15699, 14025, 13331,  9501]),\n",
       " 'labels': array([    1, 14447, 15991, 11806, 15396, 14091, 22075, 15392, 11786,\n",
       "        27368, 14554, 14038, 14328, 14048, 14410, 20122, 21354, 17400,\n",
       "        14144, 16626, 17483, 16527, 15735,  9103, 14159, 14174, 11950,\n",
       "        14297, 14596, 14527, 14038, 14288, 14517, 19754,  1700,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8de69c-1cd7-47e1-959a-52fd76a5212b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 852)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.str.len().max(), val.text.str.len().max(), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5d583-b424-4621-94dd-18b55d51bebb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ecda25d-f454-4cca-b97e-7acd831c16b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('gogamza/kobart-base-v1').to(device)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3c5dc9d-e93d-435e-9428-3b1246a69071",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3311b471-69ec-41cf-b50f-a1006ce6dfe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    print(tokenizer.decode(labels[0]), tokenizer.decode(preds[0]))\n",
    "\n",
    "    return {\n",
    "        \"avg cos\" : None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5475b55-7dae-45bf-bc77-9ccdcdec4270",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n",
      "C:\\Users\\hist\\miniconda3\\envs\\py38\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 73340\n",
      "  Num Epochs = 1000\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 2291000\n",
      "  Number of trainable parameters = 123859968\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='2291000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     21/2291000 00:35 < 1204:53:31, 0.53 it/s, Epoch 0.01/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Avg cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.972100</td>\n",
       "      <td>2.448869</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.542800</td>\n",
       "      <td>2.123150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.167700</td>\n",
       "      <td>1.831461</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.898400</td>\n",
       "      <td>1.572929</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.672600</td>\n",
       "      <td>1.333841</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.392200</td>\n",
       "      <td>1.124837</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>0.946002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.979600</td>\n",
       "      <td>0.796727</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.823700</td>\n",
       "      <td>0.672356</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.693900</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위, 코로나19 확산에 따른 사업자의 부담 경감 위해 사업자가 기</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-2\n",
      "Configuration saved in models\\checkpoint-2\\config.json\n",
      "Configuration saved in models\\checkpoint-2\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-2\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-2\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-2\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-20] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위, 코로나19 확산에 따른 영향 사업자가 자료 제출 부담 완화 조치 시행</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-4\n",
      "Configuration saved in models\\checkpoint-4\\config.json\n",
      "Configuration saved in models\\checkpoint-4\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-4\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-4\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-4\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-22] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위, 코로나19 확산에 따른 사업자의 자료 제출 부담 완화 조치 시행</s><pad>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-6\n",
      "Configuration saved in models\\checkpoint-6\\config.json\n",
      "Configuration saved in models\\checkpoint-6\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-6\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-6\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-6\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-2] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위는 코로나19 확산에 따른 사업자의 부담 완화 조치 시행</s><pad><pad><pad>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-8\n",
      "Configuration saved in models\\checkpoint-8\\config.json\n",
      "Configuration saved in models\\checkpoint-8\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-8\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-8\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-8\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-4] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위는 코로나19 확산에 따른 사업자의 부담 완화 조치들을 시행</s><pad><pad>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-10\n",
      "Configuration saved in models\\checkpoint-10\\config.json\n",
      "Configuration saved in models\\checkpoint-10\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-10\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-10\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-10\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-6] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위는 코로나19 확산으로 인한 사업자의 자료 제출 부담 완화 조치들을 시행</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-12\n",
      "Configuration saved in models\\checkpoint-12\\config.json\n",
      "Configuration saved in models\\checkpoint-12\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-12\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-12\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-12\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-8] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위는 코로나19 확산에 따른 사업자의 자료 제출 부담 완화 조치들을 시행</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-14\n",
      "Configuration saved in models\\checkpoint-14\\config.json\n",
      "Configuration saved in models\\checkpoint-14\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-14\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-14\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-14\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-10] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s> 공정위는 코로나19 확산에 따른 사업자의 자료 제출 부담 완화 조치들을 시행</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-16\n",
      "Configuration saved in models\\checkpoint-16\\config.json\n",
      "Configuration saved in models\\checkpoint-16\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-16\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-16\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-16\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-12] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-18\n",
      "Configuration saved in models\\checkpoint-18\\config.json\n",
      "Configuration saved in models\\checkpoint-18\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-18\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-18\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-18\\special_tokens_map.json\n",
      "Deleting older checkpoint [models\\checkpoint-14] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 사업자에게 각종 자료 제출의무를 부과하고 있는 공정위는 원칙적으로 기한 내에 자료를 제출하지 않으면 과태료를 부과하나 코로나19 확산에 대응하여 부담 경감 조치들을 시행한다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> </s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models\\checkpoint-20\n",
      "Configuration saved in models\\checkpoint-20\\config.json\n",
      "Configuration saved in models\\checkpoint-20\\generation_config.json\n",
      "Model weights saved in models\\checkpoint-20\\pytorch_model.bin\n",
      "tokenizer config file saved in models\\checkpoint-20\\tokenizer_config.json\n",
      "Special tokens file saved in models\\checkpoint-20\\special_tokens_map.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 26\u001b[0m\n\u001b[0;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKoBARTSum\u001b[39m\u001b[38;5;124m'\u001b[39m,                    \u001b[38;5;66;03m# 모델이름\u001b[39;00m\n\u001b[0;32m      2\u001b[0m                                 output_dir\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,                      \u001b[38;5;66;03m# 모델저장경로\u001b[39;00m\n\u001b[0;32m      3\u001b[0m                                 evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,                \u001b[38;5;66;03m# 모델의 평가를 언제 진행할지\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m                                 do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m                                 predict_with_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[0;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m                          tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     20\u001b[0m                          args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m                          callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39mstop)],\n\u001b[0;32m     25\u001b[0m                          data_collator\u001b[38;5;241m=\u001b[39mcollator,) \u001b[38;5;66;03m# callback\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\transformers\\trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1540\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1542\u001b[0m )\n\u001b[1;32m-> 1543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\transformers\\trainer.py:1868\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1868\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\transformers\\trainer.py:2135\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 2135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\transformers\\trainer.py:2226\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2223\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, SCALER_NAME))\n\u001b[0;32m   2224\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed:\n\u001b[0;32m   2225\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[1;32m-> 2226\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m caught_warnings:\n\u001b[0;32m   2228\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, SCHEDULER_NAME))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\serialization.py:423\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 423\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\serialization.py:647\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# given that we copy things around anyway, we might use storage.cpu()\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;66;03m# this means to that to get tensors serialized, you need to implement\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;66;03m# .cpu() on the underlying Storage\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 647\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m    649\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(run_name = f'KoBARTSum',                    # 모델이름\n",
    "                                output_dir= f\"models\",                      # 모델저장경로\n",
    "                                evaluation_strategy=\"steps\",                # 모델의 평가를 언제 진행할지\n",
    "                                eval_steps=2,                              # 500 스텝 마다 모델 평가\n",
    "                                save_steps=2,                              # 500 스텝 마다 모델 저장\n",
    "                                save_total_limit = 2,                       # 저장할 모델의 갯수\n",
    "                                logging_steps=2,                           # 학습로스 로깅\n",
    "                                per_device_train_batch_size=batch,          \n",
    "                                per_device_eval_batch_size=batch,                      \n",
    "                                gradient_accumulation_steps=16,             # 가상배치\n",
    "                                num_train_epochs=epoch,                                \n",
    "                                load_best_model_at_end=True,                # 평가기준 스코어가 좋은 모델만 저장할지 여부\n",
    "                                fp16=True,\n",
    "                                do_train=True,\n",
    "                                do_eval=True,\n",
    "                                predict_with_generate=True,)\n",
    "\n",
    "trainer = Seq2SeqTrainer(model=model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         args=args,\n",
    "                         train_dataset=train_dataset,\n",
    "                         eval_dataset=val_dataset,\n",
    "                         compute_metrics=compute_metrics,\n",
    "                         callbacks=[EarlyStoppingCallback(early_stopping_patience=stop)],\n",
    "                         data_collator=collator,) # callback\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c491f5-340e-42cb-ac2f-be3f60829f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f91d7a-e2ae-40e7-8b13-14171d004205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced279d-1186-43c4-ae11-b29df89e91e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
